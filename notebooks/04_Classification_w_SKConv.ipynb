{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "72X7crCFp-fk",
        "hGC3neMfqASt",
        "MPYX_AhCqCTN",
        "8J3hk569F9sg",
        "QZlTm08bGJQo",
        "6xNBeglZqHz2",
        "i4wQ816xqJ59",
        "DXrHfBRWqUwq",
        "dI0AgLWujwUi",
        "HUXe5dBvuYl4",
        "eILmMNgA3xer",
        "WdpxFhYTFDG7",
        "bnhqDtonJCHk",
        "J1VAJY2Dqmft",
        "xXdKB7UnHc-I",
        "rCHbL0GuJozs",
        "BbfMrKWcz5aZ",
        "4h5zjS-FS8mu"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize"
      ],
      "metadata": {
        "id": "R60TjtJgp8Q-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## libraries"
      ],
      "metadata": {
        "id": "72X7crCFp-fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "import pandas as pd\n",
        "import pickle as pkl\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "\n",
        "import albumentations as A\n",
        "from skimage.io import imread\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, concatenate, Conv2DTranspose, Concatenate, Multiply, Resizing, DepthwiseConv2D, Lambda, Softmax\n",
        "from tensorflow.keras.layers import BatchNormalization, Input, Activation, Add, GlobalAveragePooling2D, Reshape, Dense, multiply, Permute, maximum, Layer\n",
        "from keras.initializers import he_normal\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow import keras\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "YyfBdg_3n17M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## paths"
      ],
      "metadata": {
        "id": "hGC3neMfqASt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWlWrhJHmukD"
      },
      "outputs": [],
      "source": [
        "ROOT = '/content/drive/MyDrive/xBD_dataset'\n",
        "\n",
        "test = 'xView2_test/test/'\n",
        "train = 'xView2_train/train/'\n",
        "hold = 'xView2_hold/hold/'\n",
        "tier3 = 'xView2_tier3/tier3/'\n",
        "\n",
        "SUB = ['images', 'labels', 'targets']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## database"
      ],
      "metadata": {
        "id": "MPYX_AhCqCTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f'{ROOT}/All_Data_Props.pkl', 'rb') as f:\n",
        "    db = pkl.load(f)"
      ],
      "metadata": {
        "id": "6V3Pygp6n9n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## data generator"
      ],
      "metadata": {
        "id": "bkN5-rwzqEb1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generator for localization\n",
        "if LOCALIZATION is going to be done, use this data generator"
      ],
      "metadata": {
        "id": "8J3hk569F9sg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class xBD_DataGenerator_(keras.utils.Sequence):\n",
        "    def __init__(self, path_to_jsons, batch_size=5, patch_size=256, shuffle=True):\n",
        "\n",
        "        # Initialization -->\n",
        "        self.path_to_jsons = path_to_jsons\n",
        "        self.pre_img_paths = []\n",
        "        self.loc_target_paths = []\n",
        "\n",
        "        for i in range(len(self.path_to_jsons)):\n",
        "            # pre-disaster images\n",
        "            self.pre_img_paths.append(self.path_to_jsons[i].replace('Shareddrives/UnlimitedDrive/Thesis', 'MyDrive').replace('/labels/', '/images/').replace('_post_', '_pre_') + '.png')\n",
        "            if 'tier3' not in self.path_to_jsons[i]:\n",
        "              # localization targets\n",
        "              self.loc_target_paths.append(self.path_to_jsons[i].replace('Shareddrives/UnlimitedDrive/Thesis', 'MyDrive').replace('/labels/', '/targets/').replace('_post_', '_pre_') + '_target.png')\n",
        "            else:\n",
        "              # localization targets\n",
        "              self.loc_target_paths.append(self.path_to_jsons[i].replace('Shareddrives/UnlimitedDrive/Thesis', 'MyDrive').replace('/labels/', '/targets/').replace('_post_', '_pre_') + '.png')\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.patch_size = patch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(self.pre_img_paths))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        # Denotes the number of batches per epoch (steps per epoch) [N_batch]\n",
        "        return int(len(self.pre_img_paths) // self.batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Returns image indices of a batch\n",
        "        # Generate one batch of data\n",
        "        batch_indices = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "        pre_image_batch = list(np.array(self.pre_img_paths)[batch_indices])\n",
        "        loc_target_batch = list(np.array(self.loc_target_paths)[batch_indices])\n",
        "\n",
        "        # Generates data containing batch_size samples # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        x_pre_batch = np.empty((self.batch_size,) + (self.patch_size, self.patch_size) + (3,), dtype='float32')\n",
        "        y_target_batch = np.empty((self.batch_size,) + (self.patch_size, self.patch_size) + (1,), dtype='float32')\n",
        "        # Generate data\n",
        "        for b in range(self.batch_size):\n",
        "            pre_image = imread(pre_image_batch[b])\n",
        "            target_image = imread(loc_target_batch[b])\n",
        "\n",
        "            # Perform a random cropping and put images into batch array.\n",
        "            r_start, c_start = np.random.randint(low=0, high=(pre_image.shape[0] - self.patch_size), size=2)\n",
        "            x_pre_batch[b] = pre_image[r_start:r_start+self.patch_size, c_start:c_start+self.patch_size, :]\n",
        "            y_target_batch[b, :, :, 0] = target_image[r_start:r_start+self.patch_size, c_start:c_start+self.patch_size]\n",
        "            # y_target_batch[b, :, :, 1] = 1 - target_image[r_start:r_start+self.patch_size, c_start:c_start+self.patch_size]\n",
        "\n",
        "        return x_pre_batch, y_target_batch\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # Updates indices after each epoch\n",
        "        self.indices = np.arange(len(self.pre_img_paths))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)"
      ],
      "metadata": {
        "id": "Z_xDwjjmoCQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generator for classification\n",
        "If CLASSIFICATION is gonna be done, use this one. It returns both PRE and POST images; also, the MASK is in a one-hot format (each class in one channel)."
      ],
      "metadata": {
        "id": "QZlTm08bGJQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class xBD_DataGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, path_to_jsons, batch_size=5, patch_size=256,\n",
        "                 shuffle=True, classification=True):\n",
        "\n",
        "        # Initialization -->\n",
        "        self.path_to_jsons = path_to_jsons\n",
        "        self.pre_img_paths = []\n",
        "        self.post_img_paths = []\n",
        "        self.loc_target_paths = []\n",
        "        self.cls_target_paths = []\n",
        "\n",
        "        for i in range(len(self.path_to_jsons)):\n",
        "            # pre-disaster images\n",
        "            self.pre_img_paths.append(self.path_to_jsons[i].replace('Shareddrives/UnlimitedDrive/Thesis', 'MyDrive').replace('/labels/', '/images/').replace('_post_', '_pre_') + '.png')\n",
        "            # post-disaster images\n",
        "            self.post_img_paths.append(self.path_to_jsons[i].replace('Shareddrives/UnlimitedDrive/Thesis', 'MyDrive').replace('/labels/', '/images/') + '.png')\n",
        "            if 'tier3' not in self.path_to_jsons[i]:\n",
        "              # localization targets\n",
        "              self.loc_target_paths.append(self.path_to_jsons[i].replace('Shareddrives/UnlimitedDrive/Thesis', 'MyDrive').replace('/labels/', '/targets/').replace('_post_', '_pre_') + '_target.png')\n",
        "              # classification targets\n",
        "              self.cls_target_paths.append(self.path_to_jsons[i].replace('Shareddrives/UnlimitedDrive/Thesis', 'MyDrive').replace('/labels/', '/targets/') + '_target.png')\n",
        "            else:\n",
        "              # localization targets\n",
        "              self.loc_target_paths.append(self.path_to_jsons[i].replace('Shareddrives/UnlimitedDrive/Thesis', 'MyDrive').replace('/labels/', '/targets/').replace('_post_', '_pre_') + '.png')\n",
        "              # classification targets\n",
        "              self.cls_target_paths.append(self.path_to_jsons[i].replace('Shareddrives/UnlimitedDrive/Thesis', 'MyDrive').replace('/labels/', '/targets/') + '.png')\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.patch_size = patch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.classification = classification    # Whether you want to perform classification or localization.\n",
        "        self.indices = np.arange(len(self.pre_img_paths))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        # Denotes the number of batches per epoch (steps per epoch) [N_batch]\n",
        "        return int(len(self.pre_img_paths) // self.batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Returns image indices of a batch\n",
        "        # Generate one batch of data\n",
        "        batch_indices = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "        pre_image_batch = list(np.array(self.pre_img_paths)[batch_indices])\n",
        "        post_image_batch = list(np.array(self.post_img_paths)[batch_indices])\n",
        "        loc_target_batch = list(np.array(self.loc_target_paths)[batch_indices])\n",
        "        cls_target_batch = list(np.array(self.cls_target_paths)[batch_indices])\n",
        "\n",
        "        # Generates data containing batch_size samples # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        x_pre_batch = np.empty((self.batch_size,) + (self.patch_size, self.patch_size) + (3,), dtype='float32')\n",
        "        x_post_batch = np.empty((self.batch_size,) + (self.patch_size, self.patch_size) + (3,), dtype='float32')\n",
        "        y_target_batch = np.empty((self.batch_size,) + (self.patch_size, self.patch_size) + (5,), dtype='float32')\n",
        "        # Generate data\n",
        "        for b in range(self.batch_size):\n",
        "            pre_image = imread(pre_image_batch[b])\n",
        "            post_image = imread(post_image_batch[b])\n",
        "            if self.classification:\n",
        "                target_image = imread(cls_target_batch[b])\n",
        "                # Treat \"unclassified\" as no-damage\n",
        "                target_image[target_image == 5] = 1\n",
        "\n",
        "                # for CATEGORICAL ONE-HOT classes\n",
        "                categorical = np.zeros((target_image.shape[0], target_image.shape[1], 5))\n",
        "                categorical[:, :, 0] = target_image == 0\n",
        "                categorical[:, :, 1] = target_image == 1\n",
        "                categorical[:, :, 2] = target_image == 2\n",
        "                categorical[:, :, 3] = target_image == 3\n",
        "                categorical[:, :, 4] = target_image == 4\n",
        "                target_image = categorical\n",
        "\n",
        "            else:\n",
        "                target_image = imread(loc_target_batch[b])\n",
        "\n",
        "            # AUGMENTATION TO BE ADDED #\n",
        "\n",
        "            # Perform a random cropping and put images into batch array.\n",
        "            r_start, c_start = np.random.randint(low=0, high=(pre_image.shape[0] - self.patch_size), size=2)\n",
        "            x_pre_batch[b] = pre_image[r_start:r_start+self.patch_size, c_start:c_start+self.patch_size, :]\n",
        "            x_post_batch[b] = post_image[r_start:r_start+self.patch_size, c_start:c_start+self.patch_size, :]\n",
        "            y_target_batch[b] = target_image[r_start:r_start+self.patch_size, c_start:c_start+self.patch_size, :]\n",
        "\n",
        "        return (x_pre_batch, x_post_batch), y_target_batch\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # Updates indices after each epoch\n",
        "        self.indices = np.arange(len(self.pre_img_paths))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)"
      ],
      "metadata": {
        "id": "3MkwFfGVGJsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## data split"
      ],
      "metadata": {
        "id": "6xNBeglZqHz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data generation\n",
        "training_files = []\n",
        "cond00 = db['Group'] == 'Train'                # use images in Train folder\n",
        "cond01 = db['Group'] == 'Tier3'                # use images in Train folder\n",
        "cond1 = db['buildings#'] > 20                 # ensure there are buildings\n",
        "cond2 = db['Pre_Post'] == 'post'              # choose from pre or post\n",
        "cond3 = db['destroyed#'] + db['minor-damage#'] + db['major-damage#'] > 10\n",
        "training_files = list(db[(cond00 | cond01) & cond2 & cond3]['img_name'])\n",
        "# training_files = list(db[cond00 & cond2 & cond3]['img_name'])\n",
        "print(len(training_files))\n",
        "\n",
        "# Testing data generation\n",
        "testing_files = []\n",
        "cond0 = db['Group'] == 'Test'                 # use images in Train folder\n",
        "cond1 = db['destroyed#'] > 0                  # ensure there are buildings\n",
        "cond2 = db['Pre_Post'] == 'post'              # choose from pre or post\n",
        "cond3 = db['destroyed#'] + db['major-damage#'] + db['minor-damage#'] > 5\n",
        "testing_files = list(db[cond0 & cond2 & cond3]['img_name'])\n",
        "print(len(testing_files))\n",
        "\n",
        "# Validation data generation\n",
        "validation_files = []\n",
        "cond0 = db['Group'] == 'Hold'                 # use images in Train folder\n",
        "cond1 = db['buildings#'] > 30                 # ensure there are buildings\n",
        "cond2 = db['Pre_Post'] == 'post'              # choose from pre or post\n",
        "cond3 = db['destroyed#'] + db['minor-damage#'] + db['major-damage#'] > 20\n",
        "validation_files = list(db[cond0 & cond2 & cond3]['img_name'])\n",
        "print(len(validation_files))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSVEdI0xo_UU",
        "outputId": "c9dcbfe4-4118-4b96-a93d-50ce4fb12f6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1310\n",
            "292\n",
            "155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "i4wQ816xqJ59"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## base UNet"
      ],
      "metadata": {
        "id": "DXrHfBRWqUwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def base_unet(filters, output_channels, width=None, height=None, input_channels=1, conv_layers=2):\n",
        "    def conv2d(layer_input, filters, conv_layers=2):\n",
        "        d = Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), padding='same')(layer_input)\n",
        "        d = BatchNormalization()(d)\n",
        "        d = Activation('relu')(d)\n",
        "\n",
        "        for i in range(conv_layers - 1):\n",
        "            d = Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), padding='same')(d)\n",
        "            d = BatchNormalization()(d)\n",
        "            d = Activation('relu')(d)\n",
        "\n",
        "        return d\n",
        "\n",
        "    def deconv2d(layer_input, filters):\n",
        "        u = Conv2DTranspose(filters, 2, strides=(2, 2), padding='same')(layer_input)\n",
        "        u = BatchNormalization()(u)\n",
        "        u = Activation('relu')(u)\n",
        "        return u\n",
        "\n",
        "    inputs = Input(shape=(width, height, input_channels))\n",
        "\n",
        "    conv1 = conv2d(inputs, filters, conv_layers=conv_layers)\n",
        "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
        "\n",
        "    conv2 = conv2d(pool1, filters * 2, conv_layers=conv_layers)\n",
        "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
        "\n",
        "    conv3 = conv2d(pool2, filters * 4, conv_layers=conv_layers)\n",
        "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
        "\n",
        "    conv4 = conv2d(pool3, filters * 8, conv_layers=conv_layers)\n",
        "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
        "\n",
        "    conv5 = conv2d(pool4, filters * 16, conv_layers=conv_layers)\n",
        "\n",
        "    up6 = deconv2d(conv5, filters * 8)\n",
        "    up6 = Concatenate()([up6, conv4])\n",
        "    conv6 = conv2d(up6, filters * 8, conv_layers=conv_layers)\n",
        "\n",
        "    up7 = deconv2d(conv6, filters * 4)\n",
        "    up7 = Concatenate()([up7, conv3])\n",
        "    conv7 = conv2d(up7, filters * 4, conv_layers=conv_layers)\n",
        "\n",
        "    up8 = deconv2d(conv7, filters * 2)\n",
        "    up8 = Concatenate()([up8, conv2])\n",
        "    conv8 = conv2d(up8, filters * 2, conv_layers=conv_layers)\n",
        "\n",
        "    up9 = deconv2d(conv8, filters)\n",
        "    up9 = Concatenate()([up9, conv1])\n",
        "    conv9 = conv2d(up9, filters, conv_layers=conv_layers)\n",
        "\n",
        "    # Changed sigmoid to softmax, also changed output from 1 to 4\n",
        "    outputs = Conv2D(output_channels, kernel_size=(1, 1), strides=(1, 1), activation='sigmoid')(conv9)  # softmax\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "hsuDmY3xqKM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## residual-UNet"
      ],
      "metadata": {
        "id": "dI0AgLWujwUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_unet(filters, output_channels, width=None, height=None, input_channels=1, conv_layers=2):\n",
        "    def residual_block(x, filters, conv_layers=2):\n",
        "        x = Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "        d = x\n",
        "        for i in range(conv_layers - 1):\n",
        "            d = Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), padding='same')(d)\n",
        "            d = BatchNormalization()(d)\n",
        "            d = Activation('relu')(d)\n",
        "\n",
        "        x = Add()([d, x])\n",
        "\n",
        "        return x\n",
        "\n",
        "    def deconv2d(layer_input, filters):\n",
        "        u = Conv2DTranspose(filters, 2, strides=(2, 2), padding='same')(layer_input)\n",
        "        u = BatchNormalization()(u)\n",
        "        u = Activation('relu')(u)\n",
        "        return u\n",
        "\n",
        "    inputs = Input(shape=(width, height, input_channels))\n",
        "\n",
        "    conv1 = residual_block(inputs, filters, conv_layers=conv_layers)\n",
        "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
        "\n",
        "    conv2 = residual_block(pool1, filters * 2, conv_layers=conv_layers)\n",
        "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
        "\n",
        "    conv3 = residual_block(pool2, filters * 4, conv_layers=conv_layers)\n",
        "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
        "\n",
        "    conv4 = residual_block(pool3, filters * 8, conv_layers=conv_layers)\n",
        "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
        "\n",
        "    conv5 = residual_block(pool4, filters * 16, conv_layers=conv_layers)\n",
        "\n",
        "    conv6 = deconv2d(conv5, filters * 8)\n",
        "    up6 = concatenate([conv6, conv4])\n",
        "    up6 = residual_block(up6, filters * 8, conv_layers=conv_layers)\n",
        "\n",
        "    conv7 = deconv2d(up6, filters * 4)\n",
        "    up7 = concatenate([conv7, conv3])\n",
        "    up7 = residual_block(up7, filters * 4, conv_layers=conv_layers)\n",
        "\n",
        "    conv8 = deconv2d(up7, filters * 2)\n",
        "    up8 = concatenate([conv8, conv2])\n",
        "    up8 = residual_block(up8, filters * 2, conv_layers=conv_layers)\n",
        "\n",
        "    conv9 = deconv2d(up8, filters)\n",
        "    up9 = concatenate([conv9, conv1])\n",
        "    up9 = residual_block(up9, filters, conv_layers=conv_layers)\n",
        "\n",
        "    output_layer_noActi = Conv2D(output_channels, (1, 1), padding=\"same\", activation=None)(up9)\n",
        "    outputs = Activation('sigmoid')(output_layer_noActi)        # softmax\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "sYYUCRw8j2Sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## attention-UNet"
      ],
      "metadata": {
        "id": "HUXe5dBvuYl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def attention_unet(filters, output_channels, width=None, height=None, input_channels=1, conv_layers=2):\n",
        "    def conv2d(layer_input, filters, conv_layers=2):\n",
        "        d = Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), padding='same')(layer_input)\n",
        "        d = BatchNormalization()(d)\n",
        "        d = Activation('relu')(d)\n",
        "\n",
        "        for i in range(conv_layers - 1):\n",
        "            d = Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), padding='same')(d)\n",
        "            d = BatchNormalization()(d)\n",
        "            d = Activation('relu')(d)\n",
        "\n",
        "        return d\n",
        "\n",
        "    def deconv2d(layer_input, filters):\n",
        "        u = Conv2DTranspose(filters, 2, strides=(2, 2), padding='same')(layer_input)\n",
        "        u = BatchNormalization()(u)\n",
        "        u = Activation('relu')(u)\n",
        "        return u\n",
        "\n",
        "    def attention_block(F_g, F_l, F_int):\n",
        "        g = Conv2D(F_int, kernel_size=(1, 1), strides=(1, 1), padding='valid')(F_g)\n",
        "        g = BatchNormalization()(g)\n",
        "        x = Conv2D(F_int, kernel_size=(1, 1), strides=(1, 1), padding='valid')(F_l)\n",
        "        x = BatchNormalization()(x)\n",
        "        psi = Add()([g, x])\n",
        "        psi = Activation('relu')(psi)\n",
        "\n",
        "        psi = Conv2D(1, kernel_size=(1, 1), strides=(1, 1), padding='valid')(psi)\n",
        "        psi = Activation('sigmoid')(psi)\n",
        "\n",
        "        return Multiply()([F_l, psi])\n",
        "\n",
        "    inputs = Input(shape=(width, height, input_channels))\n",
        "\n",
        "    conv1 = conv2d(inputs, filters, conv_layers=conv_layers)\n",
        "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
        "\n",
        "    conv2 = conv2d(pool1, filters * 2, conv_layers=conv_layers)\n",
        "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
        "\n",
        "    conv3 = conv2d(pool2, filters * 4, conv_layers=conv_layers)\n",
        "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
        "\n",
        "    conv4 = conv2d(pool3, filters * 8, conv_layers=conv_layers)\n",
        "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
        "\n",
        "    conv5 = conv2d(pool4, filters * 16, conv_layers=conv_layers)\n",
        "\n",
        "    up6 = deconv2d(conv5, filters * 8)\n",
        "    conv6 = attention_block(up6, conv4, filters * 8)\n",
        "    up6 = Concatenate()([up6, conv6])\n",
        "    conv6 = conv2d(up6, filters * 8, conv_layers=conv_layers)\n",
        "\n",
        "    up7 = deconv2d(conv6, filters * 4)\n",
        "    conv7 = attention_block(up7, conv3, filters * 4)\n",
        "    up7 = Concatenate()([up7, conv7])\n",
        "    conv7 = conv2d(up7, filters * 4, conv_layers=conv_layers)\n",
        "\n",
        "    up8 = deconv2d(conv7, filters * 2)\n",
        "    conv8 = attention_block(up8, conv2, filters * 2)\n",
        "    up8 = Concatenate()([up8, conv8])\n",
        "    conv8 = conv2d(up8, filters * 2, conv_layers=conv_layers)\n",
        "\n",
        "    up9 = deconv2d(conv8, filters)\n",
        "    conv9 = attention_block(up9, conv1, filters)\n",
        "    up9 = Concatenate()([up9, conv9])\n",
        "    conv9 = conv2d(up9, filters, conv_layers=conv_layers)\n",
        "\n",
        "    outputs = Conv2D(output_channels, kernel_size=(1, 1), strides=(1, 1), activation='sigmoid')(conv9)  # softmax\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "SSuDt85quXl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "L4kozOJrqjht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## parameters"
      ],
      "metadata": {
        "id": "eILmMNgA3xer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NAME = 'UNET_WCCE_G32_K3'   # Put a custom name here\n",
        "BATCH = 5            # Define batch size for processing\n",
        "PATCH = 320          # Define patch size for cropping. Patches are square.\n",
        "EPOCHS = 150         # How many epochs?\n",
        "# CLASSES = ['buildings']                                                 # Localization\n",
        "CLASSES = ['no-damage', 'minor-damage', 'major-damage', 'destroyed']    # Classification\n",
        "n_classes = 1 if len(CLASSES) == 1 else (len(CLASSES) + 1)  # case for binary and multiclass segmentation\n",
        "\n",
        "if n_classes == 1:\n",
        "  TASK = 'localization'\n",
        "else:\n",
        "  TASK = 'classification'\n",
        "\n",
        "# Where to save the model ?!\n",
        "save_name = f'/content/drive/MyDrive/model_{NAME}_{TASK}_{BATCH}_{PATCH}_{dt.datetime.now().strftime(\"%d%m%Y-%H%M%S\")}.h5'\n",
        "\n",
        "parameters = {'shuffle': True, 'batch_size': BATCH, 'patch_size': PATCH}    # , classification=True}\n",
        "\n",
        "train_generator = xBD_DataGenerator(path_to_jsons=training_files, **parameters)\n",
        "test_generator = xBD_DataGenerator(path_to_jsons=testing_files, **parameters)\n",
        "valid_generator = xBD_DataGenerator(path_to_jsons=validation_files, **parameters)"
      ],
      "metadata": {
        "id": "niRv9ct4vZIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## loss functions\n",
        "\n",
        "https://github.com/shruti-jadon/Semantic-Segmentation-Loss-Functions"
      ],
      "metadata": {
        "id": "WdpxFhYTFDG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.losses import binary_crossentropy, BinaryCrossentropy, CategoricalCrossentropy, categorical_crossentropy\n",
        "\n",
        "beta = 0.25\n",
        "alpha = 0.25\n",
        "gamma = 2\n",
        "epsilon = 1e-5\n",
        "smooth = 1\n",
        "\n",
        "\n",
        "class Semantic_loss_functions(object):\n",
        "    def __init__(self):\n",
        "        print(\"semantic loss functions initialized\")\n",
        "\n",
        "    def dice_coef(self, y_true, y_pred):\n",
        "        y_true_f = K.flatten(y_true)\n",
        "        y_pred_f = K.flatten(y_pred)\n",
        "        intersection = K.sum(y_true_f * y_pred_f)\n",
        "        return (2. * intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())\n",
        "\n",
        "    def dice_loss(self, y_true, y_pred):\n",
        "        loss = 1 - self.dice_coef(y_true, y_pred)\n",
        "        return loss\n",
        "\n",
        "    def focal_loss_with_logits(self, logits, targets, alpha, gamma, y_pred):\n",
        "        weight_a = alpha * (1 - y_pred) ** gamma * targets\n",
        "        weight_b = (1 - alpha) * y_pred ** gamma * (1 - targets)\n",
        "        return (tf.math.log1p(tf.exp(-tf.abs(logits))) + tf.nn.relu(-logits)) * (weight_a + weight_b) + logits * weight_b\n",
        "\n",
        "    def focal_loss(self, y_true, y_pred):\n",
        "        y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())\n",
        "        logits = tf.math.log(y_pred / (1 - y_pred))\n",
        "        loss = self.focal_loss_with_logits(logits=logits, targets=y_true, alpha=alpha, gamma=gamma, y_pred=y_pred)\n",
        "        return tf.reduce_mean(loss)\n",
        "\n",
        "    def tversky_index(self, y_true, y_pred):\n",
        "        y_true_pos = K.flatten(y_true)\n",
        "        y_pred_pos = K.flatten(y_pred)\n",
        "        true_pos = K.sum(y_true_pos * y_pred_pos)\n",
        "        false_neg = K.sum(y_true_pos * (1 - y_pred_pos))\n",
        "        false_pos = K.sum((1 - y_true_pos) * y_pred_pos)\n",
        "        alpha = 0.7\n",
        "        return (true_pos + smooth) / (true_pos + alpha * false_neg + (1 - alpha) * false_pos + smooth)\n",
        "\n",
        "    def tversky_loss(self, y_true, y_pred):\n",
        "        return 1 - self.tversky_index(y_true, y_pred)\n",
        "\n",
        "    def jacard_similarity(self, y_true, y_pred):\n",
        "        \"\"\" Intersection-Over-Union (IoU), also known as the Jaccard Index .\"\"\"\n",
        "        y_true_f = K.flatten(y_true)\n",
        "        y_pred_f = K.flatten(y_pred)\n",
        "\n",
        "        intersection = K.sum(y_true_f * y_pred_f)\n",
        "        union = K.sum((y_true_f + y_pred_f) - (y_true_f * y_pred_f))\n",
        "        return intersection / union\n",
        "\n",
        "    def jacard_loss(self, y_true, y_pred):\n",
        "        return 1 - self.jacard_similarity(y_true, y_pred)\n",
        "\n",
        "    def ssim_loss(self, y_true, y_pred):\n",
        "        \"\"\" Structural Similarity Index (SSIM) loss \"\"\"\n",
        "        return 1 - tf.image.ssim(y_true, y_pred, max_val=1)\n",
        "\n",
        "    def unet3p_hybrid_loss(self, y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Hybrid loss proposed in UNET 3+ (https://arxiv.org/ftp/arxiv/papers/2004/2004.08790.pdf)\n",
        "        Hybrid loss for segmentation in three-level hierarchy – pixel, patch and map-level,\n",
        "        which is able to capture both large-scale and fine structures with clear boundaries.\n",
        "        \"\"\"\n",
        "        focal_loss = self.focal_loss(y_true, y_pred)\n",
        "        ms_ssim_loss = self.ssim_loss(y_true, y_pred)\n",
        "        jacard_loss = self.jacard_loss(y_true, y_pred)\n",
        "        return focal_loss + ms_ssim_loss + jacard_loss\n",
        "\n",
        "    def basnet_hybrid_loss(self, y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Hybrid loss proposed in BASNET (https://arxiv.org/pdf/2101.04704.pdf)\n",
        "        The hybrid loss is a combination of the binary cross entropy, structural similarity\n",
        "        and intersection-over-union losses, which guide the network to learn\n",
        "        three-level (i.e., pixel-, patch- and map- level) hierarchy representations.\n",
        "        \"\"\"\n",
        "        bce_loss = BinaryCrossentropy(from_logits=False)\n",
        "        bce_loss = bce_loss(y_true, y_pred)\n",
        "\n",
        "        ms_ssim_loss = self.ssim_loss(y_true, y_pred)\n",
        "        jacard_loss = self.jacard_loss(y_true, y_pred)\n",
        "        return bce_loss + ms_ssim_loss + jacard_loss\n",
        "\n",
        "\n",
        "def weighted_categorical_crossentropy(weights):\n",
        "    \"\"\"\n",
        "    A weighted version of keras.objectives.categorical_crossentropy\n",
        "\n",
        "    Variables:\n",
        "        weights: numpy array of shape (C,) where C is the number of classes\n",
        "\n",
        "    Usage:\n",
        "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
        "        loss = weighted_categorical_crossentropy(weights)\n",
        "        model.compile(loss=loss,optimizer='adam')\n",
        "    \"\"\"\n",
        "    weights = K.variable(weights)\n",
        "\n",
        "    def loss(y_true, y_pred):\n",
        "        # scale predictions so that the class probas of each sample sum to 1\n",
        "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
        "        # clip to prevent NaN's and Inf's\n",
        "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
        "        # calc\n",
        "        loss = y_true * K.log(y_pred) * weights\n",
        "        loss = -K.sum(loss, -1)\n",
        "        return loss\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "Fx6pjlhDFGZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "semantic_loss = Semantic_loss_functions()\n",
        "# loss=semantic_loss.unet3p_hybrid_loss\n",
        "# learning_rate_reduction = ReduceLROnPlateau(monitor='val_dice_coef', patience=10, verbose=1, factor=0.5, min_lr=0.0000001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huE8JWPKIFik",
        "outputId": "29defc7e-fe99-4fcd-d1de-140112acb69a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "semantic loss functions initialized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## metrics"
      ],
      "metadata": {
        "id": "bnhqDtonJCHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Different metrics\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "metadata": {
        "id": "IcBXGBxgJEB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## callbacks"
      ],
      "metadata": {
        "id": "J1VAJY2Dqmft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decay_schedule(epoch, lr):\n",
        "    # if epoch < 5:\n",
        "    #     lr = 0.1\n",
        "    # elif (epoch >= 5) and (epoch < 15):\n",
        "    #     lr = 0.01\n",
        "    # elif (epoch >= 15) and (epoch < 30):\n",
        "    #     lr = 0.001\n",
        "    # elif epoch >= 30:\n",
        "    #     lr = 0.0001\n",
        "    #     # localization_branch.trainable = True\n",
        "\n",
        "    if epoch < 5:\n",
        "        # lr = 0.01\n",
        "        lr = 0.0001\n",
        "    elif epoch >= 5:\n",
        "        # lr = 0.0001\n",
        "        lr = 0.00001\n",
        "        localization_branch.trainable = True\n",
        "    return lr\n",
        "\n",
        "# Various Loss functions can be tested.\n",
        "# total_loss = 'binary_crossentropy'\n",
        "# total_loss = 'categorical_crossentropy'\n",
        "# total_loss = semantic_loss.dice_loss + CategoricalCrossentropy(from_logits=True)\n",
        "total_loss = weighted_categorical_crossentropy([0.5, 2, 8, 7, 8])\n",
        "# total_loss = [semantic_loss.focal_loss, semantic_loss.dice_loss]\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(decay_schedule)\n",
        "optimizer = keras.optimizers.AdamW(learning_rate=0.001)     # AdamW\n",
        "metrics = ['accuracy', precision_m, recall_m, f1_m, semantic_loss.jacard_similarity]\n",
        "\n",
        "my_callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(save_name, save_weights_only=True, save_best_only=True, mode='min'),\n",
        "    keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, start_from_epoch=35, patience=10, restore_best_weights=True),\n",
        "    # keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.33, patience=5, mode='min'),\n",
        "    lr_scheduler,\n",
        "]"
      ],
      "metadata": {
        "id": "et7dpDuSqoo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## localization branch"
      ],
      "metadata": {
        "id": "xXdKB7UnHc-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.reset_default_graph()\n",
        "\n",
        "localization_model = base_unet(32, 1, width=PATCH, height=PATCH, input_channels=3, conv_layers=4)\n",
        "localization_model.load_weights('/content/drive/MyDrive/model_BASE-UNET_localization_10_352_25082023-154620.h5')\n",
        "\n",
        "# localization_model = attention_unet(32, 1, width=PATCH, height=PATCH, input_channels=3, conv_layers=4)\n",
        "# localization_model.load_weights('/content/drive/MyDrive/model_ATTENTION-UNET_localization_10_352_26082023-212616.h5')\n",
        "\n",
        "# localization_model = residual_unet(32, 1, width=PATCH, height=PATCH, input_channels=3, conv_layers=4)\n",
        "# localization_model.load_weights('/content/drive/MyDrive/model_RESIDUAL-UNET_localization_10_352_25082023-174256.h5')\n",
        "\n",
        "# Define the localization branch\n",
        "# Check localization_model.summary() and look for the one-to-the-last layer's name. Put it down HERE...\n",
        "# localization_branch = Model(inputs=localization_model.inputs, outputs=localization_model.get_layer('activation_47').output)\n",
        "localization_branch = Model(inputs=localization_model.inputs, outputs=localization_model.layers[-2].output)\n",
        "localization_branch.trainable = False   # SHARED WEIGHTS!!!"
      ],
      "metadata": {
        "id": "JQ22k9CPHglY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ⚖ Selective Kernel Module (SKConv)"
      ],
      "metadata": {
        "id": "rCHbL0GuJozs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def SKConv(M=2, r=16, L=32, G=32, name='skconv'):\n",
        "    def wrapper(inputs):\n",
        "        b, h, w = inputs.shape[0], inputs.shape[1], inputs.shape[2]\n",
        "        # inputs_shape = tf.shape(inputs)\n",
        "        # b, h, w = inputs_shape[0], inputs_shape[1], inputs_shape[2]                 # b: batch\n",
        "        filters = inputs.get_shape().as_list()[-1]\n",
        "        d = max(filters//r, L)      # Middle channels\n",
        "\n",
        "        x = inputs\n",
        "\n",
        "        xs = []\n",
        "        for m in range(M):\n",
        "            if G == 1:\n",
        "                # _x = Conv2D(filters, kernel_size=3+m*2, dilation_rate=m+1, padding='same', use_bias=False, name=name+'_conv%d'%m)(x)\n",
        "                _x = Conv2D(filters, kernel_size=3, dilation_rate=m+1, padding='same', use_bias=False, name=name+'_conv%d'%m)(x)\n",
        "            else:\n",
        "                c = filters // G\n",
        "                # _x = DepthwiseConv2D(kernel_size=3+m*2, dilation_rate=m+1, padding='same', use_bias=False, depth_multiplier=c, name=name+'_conv%d'%m)(x)\n",
        "                _x = DepthwiseConv2D(kernel_size=3, dilation_rate=m+1, padding='same', use_bias=False, depth_multiplier=c, name=name+'_conv%d'%m)(x)\n",
        "\n",
        "                _x = Reshape([h, w, G, c, c], name=name+'_conv%d_reshape1'%m)(_x)\n",
        "                _x = Lambda(lambda x: tf.reduce_sum(x, axis=-1), output_shape=[b, h, w, G, c], name=name+'_conv%d_sum'%m)(_x)\n",
        "                _x = Reshape([h, w, filters], name=name+'_conv%d_reshape2'%m)(_x)\n",
        "\n",
        "\n",
        "            _x = BatchNormalization(name=name+'_conv%d_bn'%m)(_x)\n",
        "            _x = Activation('relu', name=name+'_conv%d_relu'%m)(_x)\n",
        "\n",
        "            xs.append(_x)\n",
        "\n",
        "        U = Add(name=name+'_add')(xs)\n",
        "        s = Lambda(lambda x: tf.reduce_mean(x, axis=[1,2], keepdims=True), output_shape=[b, 1, 1, filters], name=name+'_gap')(U)\n",
        "\n",
        "        z = Conv2D(d, 1, name=name+'_fc_z')(s)\n",
        "        z = BatchNormalization(name=name+'_fc_z_bn')(z)\n",
        "        z = Activation('relu', name=name+'_fc_z_relu')(z)\n",
        "\n",
        "        x = Conv2D(filters*M, 1, name=name+'_fc_x')(z)\n",
        "        x = Reshape([1, 1, filters, M],name=name+'_reshape')(x)\n",
        "        scale = Softmax(name=name+'_softmax')(x)\n",
        "\n",
        "        x = Lambda(lambda x: tf.stack(x, axis=-1), output_shape=[b, h, w, filters, M], name=name+'_stack')(xs) # b, h, w, c, M\n",
        "        x = Axpby(name=name+'_axpby')([scale, x])\n",
        "\n",
        "        return x\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "class Axpby(Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "        super(Axpby, self).__init__(**kwargs)\n",
        "\n",
        "  def build(self, input_shape):\n",
        "        super(Axpby, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "  def call(self, inputs):\n",
        "    \"\"\" scale: [B, 1, 1, C, M]\n",
        "        x: [B, H, W, C, M]\n",
        "    \"\"\"\n",
        "    scale, x = inputs\n",
        "    f = tf.multiply(scale, x, name='product')\n",
        "    f = tf.reduce_sum(f, axis=-1, name='sum')\n",
        "    return f\n",
        "\n",
        "  def compute_output_shape(self, input_shape):\n",
        "    return input_shape[0:4]"
      ],
      "metadata": {
        "id": "kUcgjJFxJ840"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riGh0WEvpqh5"
      },
      "source": [
        "## 🥂 Construct the siamese netowrk + segmentation head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIxUyYAwFqo6"
      },
      "outputs": [],
      "source": [
        "input_pre = Input(shape=(PATCH, PATCH, 3), name=\"pre_input\")\n",
        "output_pre = localization_branch(input_pre)\n",
        "\n",
        "input_post = Input(shape=(PATCH, PATCH, 3), name=\"post_input\")\n",
        "output_post = localization_branch(input_post)\n",
        "\n",
        "\n",
        "# Segmentation Head can be configured to get different results.\n",
        "head = Concatenate()([output_pre, output_post])\n",
        "\n",
        "# Selective Kernel ---------------------- WITHOUT\n",
        "head = SKConv(M=2, r=16, L=32, G=32)(head)\n",
        "\n",
        "# new from here -----------------\n",
        "head = BatchNormalization()(head)\n",
        "head = Activation(\"relu\")(head)\n",
        "head = Conv2D(8, (3, 3), padding='same', kernel_initializer=he_normal(), name='middle_conv')(head)\n",
        "head = BatchNormalization()(head)\n",
        "head = Activation(\"relu\")(head)\n",
        "# to here -----------------------\n",
        "head = Conv2D(n_classes, (3, 3), padding='same', kernel_initializer=he_normal(), name='class_conv')(head)\n",
        "output = Activation(\"softmax\")(head)    # sigmoid <-- 1st place winner uses sigmoid as the last layer activation.\n",
        "\n",
        "classification_model = Model([input_pre, input_post], output)                   # CLASSIFICATION MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* If your model’s output classes are NOT mutually exclusive and you can choose many of them at the same time, use a `sigmoid` function on the network’s raw outputs.\n",
        "* If your model’s output classes are mutually exclusive and you can only choose one, then use a `softmax` function on the network’s raw outputs."
      ],
      "metadata": {
        "id": "2ZiZLy5Xb1d8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## compile"
      ],
      "metadata": {
        "id": "BbfMrKWcz5aZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classification_model.compile(optimizer, loss=total_loss, metrics=metrics)"
      ],
      "metadata": {
        "id": "XzLPnJ6sz8JA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fit\n",
        "\n",
        "[class_weight](https://datascience.stackexchange.com/questions/13490/how-to-set-class-weights-for-imbalanced-classes-in-keras)"
      ],
      "metadata": {
        "id": "vM06ERENqo2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = classification_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=valid_generator,\n",
        "    use_multiprocessing=True,\n",
        "    workers=6, epochs=EPOCHS,\n",
        "    callbacks=my_callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "8dINFjNkzNFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## show classification outputs"
      ],
      "metadata": {
        "id": "906_Vyye-lhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classification_model.load_weights('/content/drive/MyDrive/model_BASE-UNET_classification_4_256_31082023-215407.h5')"
      ],
      "metadata": {
        "id": "9xHNRKAS-rpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[x_pre, x_post], y = test_generator.__getitem__(20)\n",
        "print(x_pre.shape, y.shape)\n",
        "\n",
        "a = classification_model.predict((x_pre, x_post))\n",
        "print(a.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yw0I8pGs-3w6",
        "outputId": "cc23be01-5e99-4c3a-91d9-0a02c58f3b5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 320, 320, 3) (5, 320, 320, 5)\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "(5, 320, 320, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 20))\n",
        "for i in range(5):\n",
        "    y[i, :, :, 0] = 0\n",
        "    plt.subplot(5, 8, 8*i + 1), plt.imshow(x_pre[i].astype(int) ), plt.xticks([]), plt.yticks([]), plt.title('pre image')  #\n",
        "    plt.subplot(5, 8, 8*i + 2), plt.imshow(x_post[i].astype(int) ), plt.xticks([]), plt.yticks([]), plt.title('post image')\n",
        "    # plt.subplot(5, 8, 8*i + 3), plt.imshow(y[i, :, :, 0]), plt.xticks([]), plt.yticks([]), plt.title('GT')\n",
        "    plt.subplot(5, 8, 8*i + 3), plt.imshow(np.argmax(y[i], axis=-1), vmin=0, vmax=4), plt.xticks([]), plt.yticks([]), plt.title('GT')\n",
        "    plt.subplot(5, 8, 8*i + 4), plt.imshow(a[i, :, :, 0]), plt.xticks([]), plt.yticks([]), plt.title('--')\n",
        "    plt.subplot(5, 8, 8*i + 5), plt.imshow(a[i, :, :, 1]), plt.xticks([]), plt.yticks([]), plt.title('--')\n",
        "    plt.subplot(5, 8, 8*i + 6), plt.imshow(a[i, :, :, 2]), plt.xticks([]), plt.yticks([]), plt.title('--')\n",
        "    plt.subplot(5, 8, 8*i + 7), plt.imshow(a[i, :, :, 3]), plt.xticks([]), plt.yticks([]), plt.title('--')\n",
        "    plt.subplot(5, 8, 8*i + 8), plt.imshow(a[i, :, :, 4]), plt.xticks([]), plt.yticks([]), plt.title('--')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WVKtBU7r52gG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 9))\n",
        "for i in range(5):\n",
        "    plt.subplot(5, 7, 7*i + 1), plt.imshow(x_pre[i].astype(int)), plt.xticks([]), plt.yticks([]), plt.title('pre image')\n",
        "    plt.subplot(5, 7, 7*i + 2), plt.imshow(x_post[i].astype(int)), plt.xticks([]), plt.yticks([]), plt.title('post image')\n",
        "    plt.subplot(5, 7, 7*i + 3), plt.imshow(np.argmax(y[i], axis=-1)), plt.xticks([]), plt.yticks([]), plt.title('GT')\n",
        "    plt.subplot(5, 7, 7*i + 4), plt.imshow(np.argmax(a[i], axis=-1)), plt.xticks([]), plt.yticks([]), plt.title('--')\n",
        "    plt.subplot(5, 7, 7*i + 5), plt.imshow(a[i, :, :, 1]), plt.xticks([]), plt.yticks([]), plt.title('--')\n",
        "    plt.subplot(5, 7, 7*i + 6), plt.imshow(a[i, :, :, 2]), plt.xticks([]), plt.yticks([]), plt.title('--')\n",
        "    plt.subplot(5, 7, 7*i + 7), plt.imshow(a[i, :, :, 3]), plt.xticks([]), plt.yticks([]), plt.title('--')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SFwgz4mx_ola"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## show localization outputs\n",
        "In order to be able to run these cells, the localization data-generator must be defined before."
      ],
      "metadata": {
        "id": "4h5zjS-FS8mu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "localization_model_base_unet = base_unet(32, 1, width=PATCH, height=PATCH, input_channels=3, conv_layers=4)\n",
        "localization_model_residual_unet = residual_unet(32, 1, width=PATCH, height=PATCH, input_channels=3, conv_layers=4)\n",
        "localization_model_attention_unet = attention_unet(32, 1, width=PATCH, height=PATCH, input_channels=3, conv_layers=4)\n",
        "\n",
        "localization_model_base_unet.load_weights('/content/drive/MyDrive/model_BASE-UNET_localization_10_352_25082023-154620.h5')\n",
        "localization_model_residual_unet.load_weights('/content/drive/MyDrive/model_RESIDUAL-UNET_localization_10_352_25082023-174256.h5')\n",
        "localization_model_attention_unet.load_weights('/content/drive/MyDrive/model_ATTENTION-UNET_localization_10_352_26082023-212616.h5')"
      ],
      "metadata": {
        "id": "v-T9OnNVlipe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = test_generator.__getitem__(23)\n",
        "print(x.shape, y.shape)\n",
        "\n",
        "a = localization_model_base_unet.predict(x)\n",
        "print(a.shape)\n",
        "b = localization_model_residual_unet.predict(x)\n",
        "print(b.shape)\n",
        "c = localization_model_attention_unet.predict(x)\n",
        "print(c.shape)"
      ],
      "metadata": {
        "id": "BICxZ2HSlzvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(9, 20))\n",
        "for i in range(10):\n",
        "    plt.subplot(10, 5, 5*i + 1), plt.imshow(x[i].astype(int)), plt.xticks([]), plt.yticks([]), plt.title('pre image')\n",
        "    plt.subplot(10, 5, 5*i + 2), plt.imshow(y[i, :, :, 0]), plt.xticks([]), plt.yticks([]), plt.title('GT')\n",
        "    plt.subplot(10, 5, 5*i + 3), plt.imshow(a[i, :, :, 0]), plt.xticks([]), plt.yticks([]), plt.title('UNet')\n",
        "    plt.subplot(10, 5, 5*i + 4), plt.imshow(b[i, :, :, 0]), plt.xticks([]), plt.yticks([]), plt.title('ResUNet')\n",
        "    plt.subplot(10, 5, 5*i + 5), plt.imshow(c[i, :, :, 0]), plt.xticks([]), plt.yticks([]), plt.title('a-UNet')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ppFOwFIfmPfo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}